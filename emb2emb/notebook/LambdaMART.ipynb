{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL ###\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EDA ###\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCALER ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### METRIC ###\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ETC ###\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from box import Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\n",
    "    \"data_path\":\"./data\",\n",
    "    \"X_file_name\" : \"tag_name_openai_emb_df.csv\",\n",
    "    \"y_file_name\" : \"tag_node_emb_origin.csv\",\n",
    "    \"norm\" : False, \n",
    "    \"scaling\" : True,\n",
    "    \"valid_size\":0.1,\n",
    "    \"test_size\" : 0.1,\n",
    "    \"random_state\" : 42,\n",
    "    \"n_topics\":5,\n",
    "    \"sim_path\":\"./cosine_similarity_matrix.npy\",\n",
    "    \"candidate_k\":50,\n",
    "    \"negative_k\":100,\n",
    "}\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeLGBDataSet:\n",
    "    def __init__(self,config):\n",
    "        self.config = config\n",
    "        self.X = self.load_data(config.X_file_name)\n",
    "        self.total_size=len(self.X)\n",
    "        self.y = self.load_data(config.y_file_name)\n",
    "        self.groups, self.group_score=self.create_sim_candidates(config.candidate_k,\n",
    "                                                                 config.negative_k)\n",
    "        self.X_flattened, self.y_flattened, self.group_sizes =self.make_flatten(self.X, \n",
    "                                                                                self.groups, \n",
    "                                                                                self.group_score, \n",
    "                                                                                self.total_size)\n",
    "        self.train_lgbdataset, self.valid_lgbdataset, self.X_test, self.y_test = self.random_split(\n",
    "                                                        self.X_flattened, \n",
    "                                                        self.y_flattened, \n",
    "                                                        self.group_sizes, \n",
    "                                                        config.test_size,\n",
    "                                                        config.valid_size)\n",
    "\n",
    "    def load_data(self, file_name, data_path=\"./data\"):\n",
    "        df=pd.read_csv(os.path.join(data_path, file_name))\n",
    "        tqdm.pandas(desc=\"Processing embeddings\")\n",
    "        df[\"embedding\"] = df[\"embedding\"].apply(lambda x: np.array(eval(x)))\n",
    "        return df[\"embedding\"]\n",
    "    \n",
    "    def create_sim_candidates(self, candidate_k=30, negative_k=60):\n",
    "        # def normalize_for_lda(X):\n",
    "        #     scaler = MinMaxScaler()\n",
    "        #     X_normalized = scaler.fit_transform(X)\n",
    "        #     return X_normalized\n",
    "        cosine_similarity_matrix=np.load(self.config.sim_path)        \n",
    "        groups = []  \n",
    "        group_score = [] \n",
    "        \n",
    "        for i, row in enumerate(cosine_similarity_matrix):\n",
    "            # Positive candidates\n",
    "            top_k_indices = np.argsort(-row)[:candidate_k]\n",
    "            top_k_scores = row[top_k_indices]\n",
    "            \n",
    "            # Negative candidates\n",
    "            negative_indices = np.random.choice(\n",
    "                [idx for idx in range(len(row)) if idx not in top_k_indices],\n",
    "                size=negative_k,\n",
    "                replace=False\n",
    "            )\n",
    "            negative_scores = np.zeros(len(negative_indices)) \n",
    "\n",
    "            all_indices = np.concatenate([top_k_indices, negative_indices])\n",
    "            all_scores = np.concatenate([top_k_scores, negative_scores])\n",
    "            \n",
    "            groups.append(all_indices)\n",
    "            group_score.append(all_scores)\n",
    "    \n",
    "        return groups, group_score\n",
    "    \n",
    "    def create_hard_negatives(self, candidate_k=30, hard_negative_k=60):\n",
    "        cosine_similarity_matrix=np.load(self.config.sim_path)\n",
    "        groups = []\n",
    "        group_scores = []\n",
    "    \n",
    "        for i, row in enumerate(cosine_similarity_matrix):\n",
    "            # Positive candidates\n",
    "            top_k_indices = np.argsort(-row)[:candidate_k]\n",
    "            top_k_scores = row[top_k_indices]\n",
    "            \n",
    "            # Hard Negative candidates (Middle-ranked)\n",
    "            hard_neg_indices = np.argsort(-row)[candidate_k:candidate_k + hard_negative_k]\n",
    "            hard_neg_scores = row[hard_neg_indices]\n",
    "\n",
    "            all_indices = np.concatenate([top_k_indices, hard_neg_indices])\n",
    "            all_scores = np.concatenate([top_k_scores, hard_neg_scores])\n",
    "            \n",
    "            groups.append(all_indices)\n",
    "            group_scores.append(all_scores)\n",
    "        \n",
    "        return groups, group_scores\n",
    "        \n",
    "    def create_lda_candidates(self, n_topics=config.n_topics, candidate_k=30, negative_k=60):\n",
    "        cosine_similarity_matrix=np.load(config.sim_path)\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "        lda.fit(cosine_similarity_matrix)\n",
    "        node_topic_distribution = lda.components_.T\n",
    "        node_topics_k = np.argsort(node_topic_distribution, axis=1)[:, -candidate_k:]\n",
    "        \n",
    "        groups = [] \n",
    "        for topic in range(n_topics):\n",
    "            group_indices = np.where(node_topics_k == topic)[0]\n",
    "            groups.append(group_indices)\n",
    "        \n",
    "    def make_flatten(self, X, groups, group_score, total_size):\n",
    "        X_flattened = []\n",
    "        y_flattened = []\n",
    "        group_sizes = []\n",
    "        \n",
    "        for datapoint in range(total_size):\n",
    "            candidates = groups[datapoint]\n",
    "            scores = group_score[datapoint]\n",
    "            for idx, score in zip(candidates,scores):\n",
    "                X_flattened.append(X.values[idx])\n",
    "                y_flattened.append(score) \n",
    "            group_sizes.append(len(candidates))\n",
    "            \n",
    "        y_flattened = (np.array(y_flattened) * 100).astype(int)\n",
    "        print(f\"Scaled and flattened scores: {y_flattened}\")\n",
    "        return np.array(X_flattened), y_flattened, np.array(group_sizes)\n",
    "    \n",
    "    def create_lgbdataset(self, X_flattened, y_flattened, group_sizes, reference=None):\n",
    "        lgbdataset=lgb.Dataset(X_flattened, label=y_flattened, \n",
    "                               group=group_sizes, reference=reference)\n",
    "        return lgbdataset\n",
    "    \n",
    "    def split(self, X_flattened, y_flattened, group_sizes, test_size=0.2, valid_size=0.1):\n",
    "        num_queries = len(group_sizes)  \n",
    "        \n",
    "        train_size = int((1 - test_size - valid_size) * num_queries)\n",
    "        valid_size = int(valid_size * num_queries)\n",
    "        test_size = num_queries - train_size - valid_size\n",
    "\n",
    "        train_indices = np.arange(train_size)\n",
    "        valid_indices = np.arange(train_size, train_size + valid_size)\n",
    "        test_indices = np.arange(train_size + valid_size, num_queries)\n",
    "\n",
    "        cumulative_sizes = np.cumsum(group_sizes)\n",
    "\n",
    "        train_flat_indices = np.arange(cumulative_sizes[train_indices[-1]]) if len(train_indices) > 0 else []\n",
    "        valid_flat_indices = np.arange(cumulative_sizes[train_indices[-1]], cumulative_sizes[valid_indices[-1]]) if len(valid_indices) > 0 else []\n",
    "        test_flat_indices = np.arange(cumulative_sizes[valid_indices[-1]], cumulative_sizes[-1])\n",
    "\n",
    "        X_train = X_flattened[train_flat_indices]\n",
    "        X_valid = X_flattened[valid_flat_indices]\n",
    "        X_test = X_flattened[test_flat_indices]\n",
    "        \n",
    "        y_train = y_flattened[train_flat_indices]\n",
    "        y_valid = y_flattened[valid_flat_indices]\n",
    "        y_test = y_flattened[test_flat_indices]\n",
    "        \n",
    "        group_train = group_sizes[train_indices]\n",
    "        group_valid = group_sizes[valid_indices]\n",
    "        group_test = group_sizes[test_indices]\n",
    "        \n",
    "        train_lgbdataset = self.create_lgbdataset(X_train, y_train, group_train)\n",
    "        valid_lgbdataset = self.create_lgbdataset(X_valid, y_valid, group_valid, train_lgbdataset)\n",
    "\n",
    "        return train_lgbdataset, valid_lgbdataset, X_test, y_test\n",
    "\n",
    "    def random_split(self, X_flattened, y_flattened, group_sizes, test_size=0.2, valid_size=0.1, random_state=42):\n",
    "        num_queries = len(group_sizes)\n",
    "\n",
    "        query_indices = np.arange(num_queries)\n",
    "        query_indices, group_sizes = shuffle(query_indices, group_sizes, random_state=random_state)\n",
    "\n",
    "        train_size = int((1 - test_size - valid_size) * num_queries)\n",
    "        valid_size = int(valid_size * num_queries)\n",
    "        test_size = num_queries - train_size - valid_size\n",
    "\n",
    "        train_indices = query_indices[:train_size]\n",
    "        valid_indices = query_indices[train_size:train_size + valid_size]\n",
    "        test_indices = query_indices[train_size + valid_size:]\n",
    "\n",
    "        cumulative_sizes = np.cumsum(group_sizes)\n",
    "\n",
    "        def get_flat_indices(indices):\n",
    "            flat_indices = []\n",
    "            for idx in indices:\n",
    "                start_idx = cumulative_sizes[idx - 1] if idx > 0 else 0\n",
    "                end_idx = cumulative_sizes[idx]\n",
    "                flat_indices.extend(np.arange(start_idx, end_idx))\n",
    "            return np.array(flat_indices)\n",
    "\n",
    "        train_flat_indices = get_flat_indices(train_indices)\n",
    "        valid_flat_indices = get_flat_indices(valid_indices)\n",
    "        test_flat_indices = get_flat_indices(test_indices)\n",
    "\n",
    "        X_train = X_flattened[train_flat_indices]\n",
    "        X_valid = X_flattened[valid_flat_indices]\n",
    "        X_test = X_flattened[test_flat_indices]\n",
    "\n",
    "        y_train = y_flattened[train_flat_indices]\n",
    "        y_valid = y_flattened[valid_flat_indices]\n",
    "        y_test = y_flattened[test_flat_indices]\n",
    "\n",
    "        group_train = group_sizes[train_indices]\n",
    "        group_valid = group_sizes[valid_indices]\n",
    "        group_test = group_sizes[test_indices]\n",
    "\n",
    "        train_lgbdataset = self.create_lgbdataset(X_train, y_train, group_train)\n",
    "        valid_lgbdataset = self.create_lgbdataset(X_valid, y_valid, group_valid, train_lgbdataset)\n",
    "\n",
    "        return train_lgbdataset, valid_lgbdataset, X_test, y_test    \n",
    "            \n",
    "    def get_lgbdataset(self):\n",
    "        return self.train_lgbdataset, self.valid_lgbdataset\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.X_test, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    ndcg_at_k = ndcg_score([y_true], [y_pred], k=10)  \n",
    "    \n",
    "    print(f\"NDCG@10: {ndcg_at_k:.4f}\")\n",
    "    \n",
    "    y_true_reshaped = y_true.reshape(-1, 1)\n",
    "    y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "\n",
    "    map_score = average_precision_score(y_true_reshaped, y_pred_reshaped)\n",
    "    print(f\"MAP: {map_score:.4f}\")\n",
    "    \n",
    "    def mean_reciprocal_rank(y_true, y_pred):\n",
    "        indices = np.argsort(-y_pred)\n",
    "        reciprocal_rank = 0.0\n",
    "        for i, index in enumerate(indices):\n",
    "            if y_true[index] > 0:\n",
    "                reciprocal_rank = 1 / (i + 1)\n",
    "                break\n",
    "        return reciprocal_rank\n",
    "\n",
    "    mrr = mean_reciprocal_rank(y_true, y_pred)\n",
    "    print(f\"MRR: {mrr:.4f}\")\n",
    "    \n",
    "    def accuracy_at_k(y_true, y_pred, k):\n",
    "        top_k_indices = np.argsort(-y_pred)[:k] \n",
    "        top_k_true = np.argsort(-y_true)[:k]\n",
    "        return len(set(top_k_indices) & set(top_k_true)) / k\n",
    "\n",
    "    acc_at_10 = accuracy_at_k(y_true, y_pred, 10)\n",
    "    \n",
    "    print(f\"Accuracy@10: {acc_at_10:.4f}\")\n",
    "    \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    print(f\"MSE: {mse:.4f}, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    lgbdataset=MakeLGBDataSet(config)\n",
    "    train_lgbdataset, valid_lgbdataset=lgbdataset.get_lgbdataset()\n",
    "    X_test, y_true=lgbdataset.get_test()\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"lambdarank\",\n",
    "        \"metric\": \"ndcg\",\n",
    "        \"ndcg_eval_at\": [1, 5, 10],\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 10,\n",
    "        \"label_gain\": list(range(101)),\n",
    "        \"max_depth\":15,\n",
    "        \"bagging_fraction\":0.5,\n",
    "        \"bagging_freq\":10\n",
    "    }\n",
    "    # print(f\"Label gain mapping: {params['label_gain']}\")\n",
    "    model = lgb.train(params, train_lgbdataset, valid_sets=[valid_lgbdataset], \n",
    "                    num_boost_round=100)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # print(f\"Predicted scores range: {y_pred.min()} to {y_pred.max()}\")\n",
    "    # y_pred_normalized = (y_pred - y_pred.min()) / (y_pred.max() - y_pred.min())\n",
    "    # print(f\"Normalized Predicted scores range: {y_pred_normalized.min()} to {y_pred_normalized.max()}\")\n",
    "    metric(y_true, y_pred)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8709f46d40bc9fa980f42dc08022ffe57fa483523fc00a47e1fcfe7a898438e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
